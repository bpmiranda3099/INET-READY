# INET-READY Machine Learning Documentation

This document details the machine learning models, processes, and validation techniques used in the INET-READY system for heat index prediction and risk assessment.

## Heat Index Prediction Model

### Algorithm Selection

INET-READY uses **XGBoost Regression** (`xgboost.XGBRegressor`) for heat index prediction due to its:

- Superior performance on time-series weather data
- Ability to handle non-linear relationships
- Robustness to outliers
- Efficient handling of missing values
- Excellent performance-to-complexity ratio

### Feature Engineering

The model uses these input features:

- **Day index**: Numerical representation of date (days since first record)
- **Temperature (Max/Min)**: Daily maximum and minimum temperatures
- **Apparent Temperature (Max/Min)**: "Feels like" temperature accounting for humidity and wind
- **Wind Speed**: Daily average wind speed
- **Solar Radiation**: Daily solar radiation exposure
- **Relative Humidity**: Daily average relative humidity

### Target Variable

- **Heat Index (°C)**: Calculated using the NOAA heat index equation

### Model Configuration

```python
model = XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=5,
    min_child_weight=1,
    subsample=0.8,
    colsample_bytree=0.8,
    objective='reg:squarederror',
    early_stopping_rounds=10,
    random_state=42
)
```

## Machine Learning Pipeline

### 1. Data Collection and Preprocessing

```
├── daily_historical_weather_data.py  # Collects historical weather data
├── hourly_heat_index_api.py          # Collects real-time weather data
└── validation/
    ├── data_validation.py            # Validates data quality and completeness
```

Key preprocessing steps:

- Missing value imputation using forward/backward fill
- Feature scaling (Min-Max normalization)
- Outlier detection and handling
- Time-based feature engineering (day of year, etc.)

### 2. Model Training

Training process is implemented in `predict_heat_index.py`:

1. Load and preprocess historical weather data
2. Split data into training and validation sets
3. Train XGBoost model with early stopping
4. Perform comprehensive validation (see Validation section)
5. Save trained model for production use

### 3. Prediction Generation

Daily predictions are generated by `heat_index_forecast_api.py`:

1. Load trained model
2. Fetch 7-day weather forecast from OpenMeteo
3. Apply same preprocessing steps as training
4. Generate heat index predictions for each city
5. Save results to Firestore and CSV files
6. Log model performance metrics

## Validation Methodology

INET-READY employs multiple rigorous validation techniques to ensure model reliability:

### K-Fold Cross-Validation

```python
def perform_k_fold_cross_validation(X, y, n_splits=5):
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)
    mae_scores, mse_scores, r2_scores = [], [], []

    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

        model = XGBRegressor(...)
        model.fit(X_train, y_train)

        y_pred = model.predict(X_test)
        mae_scores.append(mean_absolute_error(y_test, y_pred))
        mse_scores.append(mean_squared_error(y_test, y_pred))
        r2_scores.append(r2_score(y_test, y_pred))

    return {
        'mae': {'mean': np.mean(mae_scores), 'std': np.std(mae_scores)},
        'mse': {'mean': np.mean(mse_scores), 'std': np.std(mse_scores)},
        'r2': {'mean': np.mean(r2_scores), 'std': np.std(r2_scores)}
    }
```

### Nested Cross-Validation with Hyperparameter Tuning

```python
def perform_nested_cv_with_param_tuning(X, y, n_outer=5, n_inner=3):
    outer_cv = KFold(n_splits=n_outer, shuffle=True, random_state=42)
    param_grid = {
        'n_estimators': [50, 100, 150],
        'max_depth': [3, 5, 7],
        'learning_rate': [0.01, 0.1, 0.2]
    }

    outer_scores = []

    for train_idx, test_idx in outer_cv.split(X):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

        inner_cv = KFold(n_splits=n_inner, shuffle=True, random_state=42)
        model = GridSearchCV(
            XGBRegressor(),
            param_grid,
            cv=inner_cv,
            scoring='neg_mean_absolute_error'
        )

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        outer_scores.append(mean_absolute_error(y_test, y_pred))

    return {
        'mean_mae': np.mean(outer_scores),
        'std_mae': np.std(outer_scores),
        'best_params': model.best_params_
    }
```

### Bootstrap Evaluation

```python
def bootstrap_evaluation(X, y, n_iterations=100):
    mae_scores, mse_scores, r2_scores = [], [], []
    n_samples = len(X)

    for _ in range(n_iterations):
        indices = np.random.choice(n_samples, n_samples, replace=True)
        X_bootstrap, y_bootstrap = X.iloc[indices], y.iloc[indices]

        # Split the bootstrapped sample
        X_train, X_test, y_train, y_test = train_test_split(
            X_bootstrap, y_bootstrap, test_size=0.2, random_state=42
        )

        model = XGBRegressor(...)
        model.fit(X_train, y_train)

        y_pred = model.predict(X_test)
        mae_scores.append(mean_absolute_error(y_test, y_pred))
        mse_scores.append(mean_squared_error(y_test, y_pred))
        r2_scores.append(r2_score(y_test, y_pred))

    return {
        'mae': {'mean': np.mean(mae_scores),
                'std': np.std(mae_scores),
                '95_ci': (np.percentile(mae_scores, 2.5),
                          np.percentile(mae_scores, 97.5))},
        'mse': {'mean': np.mean(mse_scores),
                'std': np.std(mse_scores)},
        'r2': {'mean': np.mean(r2_scores),
               'std': np.std(r2_scores)}
    }
```

### Permutation Test for Feature Importance

```python
def perform_permutation_test(X, y, model, n_repeats=10):
    # Train the model on the full dataset
    model.fit(X, y)

    # Calculate feature importance using permutation importance
    perm_importance = permutation_importance(
        model, X, y, n_repeats=n_repeats, random_state=42
    )

    feature_importance = {
        'mean_importance': perm_importance.importances_mean,
        'std_importance': perm_importance.importances_std,
        'feature_names': list(X.columns)
    }

    return feature_importance
```

### Time-Based Validation

```python
def perform_time_based_validation(X, y, test_size=0.2):
    # Sort by date/time
    sorted_indices = np.argsort(X['day_index'].values)
    X_sorted, y_sorted = X.iloc[sorted_indices], y.iloc[sorted_indices]

    # Split based on time (most recent data as test)
    split_idx = int(len(X_sorted) * (1 - test_size))
    X_train, X_test = X_sorted.iloc[:split_idx], X_sorted.iloc[split_idx:]
    y_train, y_test = y_sorted.iloc[:split_idx], y_sorted.iloc[split_idx:]

    model = XGBRegressor(...)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    return {
        'mae': mean_absolute_error(y_test, y_pred),
        'mse': mean_squared_error(y_test, y_pred),
        'r2': r2_score(y_test, y_pred)
    }
```

## Model Metrics and Evaluation

The system calculates and stores the following metrics for each model:

1. **Mean Absolute Error (MAE)**

   - Average absolute difference between predicted and actual heat index values
   - Lower is better (typical range: 0.5°C to 2.0°C)

2. **Mean Squared Error (MSE)**

   - Average squared difference between predicted and actual values
   - More sensitive to outliers than MAE

3. **R² Score (Coefficient of Determination)**

   - Proportion of variance in the dependent variable predictable from independent variables
   - Range: 0 to 1, higher is better (typical values: 0.80 to 0.95)

4. **Quality Rating**
   - Composite score (0-100) calculated from MAE, MSE, and R²
   - Qualitative labels: Excellent (90-100), Good (75-89), Fair (50-74), Poor (<50)

## Model Outputs and Storage

Prediction outputs are saved in multiple formats:

1. **CSV Files**:

   - Daily predictions: `public/data/predicted_heat_index/YYYY-MM-DD_heat_index_prediction.csv`
   - Model metrics: `public/data/predicted_heat_index/YYYY-MM-DD_metrics_comparison_before.csv` and `public/data/predicted_heat_index/YYYY-MM-DD_metrics_comparison_after.csv`

2. **Firestore Database**:

   - Collection: `heat_index_predictions`
   - Document structure:
     ```
     {
       city: string,
       date: timestamp,
       heat_index: number,
       temperature: number,
       humidity: number,
       model_quality_rating: number
     }
     ```

3. **Logs**:
   - Detailed training and prediction logs: `src/scripts/logs/heat_index_prediction_YYYY-MM-DD.log`

## Conclusion

The INET-READY machine learning infrastructure uses industry-standard techniques for reliable heat index prediction. Multiple validation methods ensure model robustness, while comprehensive metrics and logging provide transparency and facilitate continuous improvement. The system automatically generates new predictions daily, ensuring users have access to the most up-to-date heat risk information.
